{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([44730, 11, 40])\n",
      "torch.Size([4773, 11, 40])\n",
      "torch.Size([44730])\n",
      "torch.Size([4773])\n",
      "(48,)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "# Load the dataset\n",
    "data = np.load('lab2_dataset.npz')\n",
    "train_feats = torch.tensor(data['train_feats'])\n",
    "test_feats = torch.tensor(data['test_feats'])\n",
    "train_labels = torch.tensor(data['train_labels'])\n",
    "test_labels = torch.tensor(data['test_labels'])\n",
    "phone_labels = data['phone_labels']\n",
    "\n",
    "print(train_feats.shape)\n",
    "print(test_feats.shape)\n",
    "print(train_labels.shape)\n",
    "print(test_labels.shape)\n",
    "print(phone_labels.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up the dataloaders\n",
    "train_dataset = torch.utils.data.TensorDataset(train_feats, train_labels)\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=8, shuffle=True)\n",
    "\n",
    "test_dataset = torch.utils.data.TensorDataset(test_feats, test_labels)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=8, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the model architecture\n",
    "class MyModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MyModel, self).__init__()\n",
    "        # TODO: Fill in the model's layers here\n",
    "\n",
    "        # self.fc1 = nn.Linear(3520, 128)\n",
    "        # self.fc2 = nn.Linear(128, 64)\n",
    "        # self.fc3 = nn.Linear(64, 48)\n",
    "\n",
    "\n",
    "        self.linear1 = nn.Linear(40, 48)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.linear2 = nn.Linear(48, 64)\n",
    "        self.linear3 = nn.Linear(64, 40)\n",
    "\n",
    "        \n",
    "        \n",
    "    def forward(self, x):\n",
    "        # TODO: Fill in the forward pass here\n",
    "        # print(x.shape)\n",
    "        # # flatten x to 1D\n",
    "        # x = x.view(x.shape[0], -1)\n",
    "        # x = x.flatten()\n",
    "        # print(x.shape)\n",
    "        # x = self.fc1(x)\n",
    "        # x = F.relu(x)\n",
    "        # print(x.shape)\n",
    "        # x = self.fc2(x)\n",
    "        # x = F.relu(x)\n",
    "        # print(x.shape)\n",
    "        # x = self.fc3(x)\n",
    "        # x = F.relu(x)\n",
    "        # print(x.shape)\n",
    "\n",
    "        x = self.linear1(x)\n",
    "        \n",
    "        x = self.relu(x)\n",
    "\n",
    "        x = self.linear2(x)\n",
    "        x = self.relu(x)\n",
    "\n",
    "        x = self.linear3(x)\n",
    "        x = self.relu(x)\n",
    "    \n",
    "        x = torch.flatten(x, 1)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the model, loss function, and optimizer\n",
    "model = MyModel()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "def train_network(model, train_loader, criterion, optimizer):\n",
    "    # TODO: fill in\n",
    "    for epoch in range(10):\n",
    "        running_loss = 0.0\n",
    "        for i, (inputs, labels) in enumerate(train_loader, 0):\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "            if i % 100 == 99:\n",
    "                print('[%d, %5d] loss: %.3f' % (epoch + 1, i + 1, running_loss / 100))\n",
    "                running_loss = 0.0\n",
    "\n",
    "def test_network(model, test_loader):\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for data in test_loader:\n",
    "            inputs, labels = data\n",
    "            outputs = model(inputs)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    print('Test accuracy: %d %%' % (100 * correct / total))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,   100] loss: 6.204\n",
      "[1,   200] loss: 6.052\n",
      "[1,   300] loss: 6.019\n",
      "[1,   400] loss: 6.017\n",
      "[1,   500] loss: 6.035\n",
      "[1,   600] loss: 6.006\n",
      "[1,   700] loss: 6.042\n",
      "[1,   800] loss: 6.024\n",
      "[1,   900] loss: 6.030\n",
      "[1,  1000] loss: 6.009\n",
      "[1,  1100] loss: 6.015\n",
      "[1,  1200] loss: 6.017\n",
      "[1,  1300] loss: 6.031\n",
      "[1,  1400] loss: 6.001\n",
      "[1,  1500] loss: 5.989\n",
      "[1,  1600] loss: 6.009\n",
      "[1,  1700] loss: 6.002\n",
      "[1,  1800] loss: 5.989\n",
      "[1,  1900] loss: 5.992\n",
      "[1,  2000] loss: 5.990\n",
      "[1,  2100] loss: 6.018\n",
      "[1,  2200] loss: 5.995\n",
      "[1,  2300] loss: 5.944\n",
      "[1,  2400] loss: 5.978\n",
      "[1,  2500] loss: 5.936\n",
      "[1,  2600] loss: 5.959\n",
      "[1,  2700] loss: 5.960\n",
      "[1,  2800] loss: 5.960\n",
      "[1,  2900] loss: 5.976\n",
      "[1,  3000] loss: 5.968\n",
      "[1,  3100] loss: 5.949\n",
      "[1,  3200] loss: 5.976\n",
      "[1,  3300] loss: 5.974\n",
      "[1,  3400] loss: 5.964\n",
      "[1,  3500] loss: 5.923\n",
      "[1,  3600] loss: 5.978\n",
      "[1,  3700] loss: 5.956\n",
      "[1,  3800] loss: 5.893\n",
      "[1,  3900] loss: 5.871\n",
      "[1,  4000] loss: 5.947\n",
      "[1,  4100] loss: 5.872\n",
      "[1,  4200] loss: 5.901\n",
      "[1,  4300] loss: 5.897\n",
      "[1,  4400] loss: 5.914\n",
      "[1,  4500] loss: 5.899\n",
      "[1,  4600] loss: 5.841\n",
      "[1,  4700] loss: 5.904\n",
      "[1,  4800] loss: 5.826\n",
      "[1,  4900] loss: 5.850\n",
      "[1,  5000] loss: 5.895\n",
      "[1,  5100] loss: 5.899\n",
      "[1,  5200] loss: 5.857\n",
      "[1,  5300] loss: 5.846\n",
      "[1,  5400] loss: 5.794\n",
      "[1,  5500] loss: 5.870\n",
      "[2,   100] loss: 5.859\n",
      "[2,   200] loss: 5.835\n",
      "[2,   300] loss: 5.857\n",
      "[2,   400] loss: 5.905\n",
      "[2,   500] loss: 5.831\n",
      "[2,   600] loss: 5.820\n",
      "[2,   700] loss: 5.843\n",
      "[2,   800] loss: 5.859\n",
      "[2,   900] loss: 5.766\n",
      "[2,  1000] loss: 5.893\n",
      "[2,  1100] loss: 5.874\n",
      "[2,  1200] loss: 5.824\n",
      "[2,  1300] loss: 5.834\n",
      "[2,  1400] loss: 5.771\n",
      "[2,  1500] loss: 5.806\n",
      "[2,  1600] loss: 5.806\n",
      "[2,  1700] loss: 5.730\n",
      "[2,  1800] loss: 5.794\n",
      "[2,  1900] loss: 5.800\n",
      "[2,  2000] loss: 5.791\n",
      "[2,  2100] loss: 5.774\n",
      "[2,  2200] loss: 5.865\n",
      "[2,  2300] loss: 5.797\n",
      "[2,  2400] loss: 5.792\n",
      "[2,  2500] loss: 5.744\n",
      "[2,  2600] loss: 5.817\n",
      "[2,  2700] loss: 5.776\n",
      "[2,  2800] loss: 5.865\n",
      "[2,  2900] loss: 5.781\n",
      "[2,  3000] loss: 5.720\n",
      "[2,  3100] loss: 5.796\n",
      "[2,  3200] loss: 5.828\n",
      "[2,  3300] loss: 5.758\n",
      "[2,  3400] loss: 5.790\n",
      "[2,  3500] loss: 5.799\n",
      "[2,  3600] loss: 5.781\n",
      "[2,  3700] loss: 5.846\n",
      "[2,  3800] loss: 5.701\n",
      "[2,  3900] loss: 5.790\n",
      "[2,  4000] loss: 5.849\n",
      "[2,  4100] loss: 5.747\n",
      "[2,  4200] loss: 5.765\n",
      "[2,  4300] loss: 5.732\n",
      "[2,  4400] loss: 5.766\n",
      "[2,  4500] loss: 5.826\n",
      "[2,  4600] loss: 5.777\n",
      "[2,  4700] loss: 5.770\n",
      "[2,  4800] loss: 5.783\n",
      "[2,  4900] loss: 5.774\n",
      "[2,  5000] loss: 5.778\n",
      "[2,  5100] loss: 5.780\n",
      "[2,  5200] loss: 5.735\n",
      "[2,  5300] loss: 5.855\n",
      "[2,  5400] loss: 5.824\n",
      "[2,  5500] loss: 5.740\n",
      "[3,   100] loss: 5.731\n",
      "[3,   200] loss: 5.801\n",
      "[3,   300] loss: 5.755\n",
      "[3,   400] loss: 5.800\n",
      "[3,   500] loss: 5.668\n",
      "[3,   600] loss: 5.663\n",
      "[3,   700] loss: 5.807\n",
      "[3,   800] loss: 5.757\n",
      "[3,   900] loss: 5.729\n",
      "[3,  1000] loss: 5.727\n",
      "[3,  1100] loss: 5.785\n",
      "[3,  1200] loss: 5.779\n",
      "[3,  1300] loss: 5.735\n",
      "[3,  1400] loss: 5.692\n",
      "[3,  1500] loss: 5.716\n",
      "[3,  1600] loss: 5.694\n",
      "[3,  1700] loss: 5.707\n",
      "[3,  1800] loss: 5.671\n",
      "[3,  1900] loss: 5.740\n",
      "[3,  2000] loss: 5.713\n",
      "[3,  2100] loss: 5.663\n",
      "[3,  2200] loss: 5.685\n",
      "[3,  2300] loss: 5.730\n",
      "[3,  2400] loss: 5.716\n",
      "[3,  2500] loss: 5.722\n",
      "[3,  2600] loss: 5.744\n",
      "[3,  2700] loss: 5.697\n",
      "[3,  2800] loss: 5.683\n",
      "[3,  2900] loss: 5.687\n",
      "[3,  3000] loss: 5.712\n",
      "[3,  3100] loss: 5.704\n",
      "[3,  3200] loss: 5.707\n",
      "[3,  3300] loss: 5.727\n",
      "[3,  3400] loss: 5.675\n",
      "[3,  3500] loss: 5.733\n",
      "[3,  3600] loss: 5.674\n",
      "[3,  3700] loss: 5.707\n",
      "[3,  3800] loss: 5.719\n",
      "[3,  3900] loss: 5.654\n",
      "[3,  4000] loss: 5.714\n",
      "[3,  4100] loss: 5.669\n",
      "[3,  4200] loss: 5.675\n",
      "[3,  4300] loss: 5.681\n",
      "[3,  4400] loss: 5.722\n",
      "[3,  4500] loss: 5.679\n",
      "[3,  4600] loss: 5.758\n",
      "[3,  4700] loss: 5.714\n",
      "[3,  4800] loss: 5.710\n",
      "[3,  4900] loss: 5.714\n",
      "[3,  5000] loss: 5.732\n",
      "[3,  5100] loss: 5.676\n",
      "[3,  5200] loss: 5.727\n",
      "[3,  5300] loss: 5.661\n",
      "[3,  5400] loss: 5.663\n",
      "[3,  5500] loss: 5.671\n",
      "[4,   100] loss: 5.681\n",
      "[4,   200] loss: 5.713\n",
      "[4,   300] loss: 5.718\n",
      "[4,   400] loss: 5.697\n",
      "[4,   500] loss: 5.685\n",
      "[4,   600] loss: 5.683\n",
      "[4,   700] loss: 5.654\n",
      "[4,   800] loss: 5.631\n",
      "[4,   900] loss: 5.710\n",
      "[4,  1000] loss: 5.698\n",
      "[4,  1100] loss: 5.645\n",
      "[4,  1200] loss: 5.676\n",
      "[4,  1300] loss: 5.682\n",
      "[4,  1400] loss: 5.664\n",
      "[4,  1500] loss: 5.690\n",
      "[4,  1600] loss: 5.705\n",
      "[4,  1700] loss: 5.634\n",
      "[4,  1800] loss: 5.684\n",
      "[4,  1900] loss: 5.746\n",
      "[4,  2000] loss: 5.645\n",
      "[4,  2100] loss: 5.652\n",
      "[4,  2200] loss: 5.674\n",
      "[4,  2300] loss: 5.658\n",
      "[4,  2400] loss: 5.692\n",
      "[4,  2500] loss: 5.645\n",
      "[4,  2600] loss: 5.703\n",
      "[4,  2700] loss: 5.659\n",
      "[4,  2800] loss: 5.654\n",
      "[4,  2900] loss: 5.654\n",
      "[4,  3000] loss: 5.699\n",
      "[4,  3100] loss: 5.654\n",
      "[4,  3200] loss: 5.695\n",
      "[4,  3300] loss: 5.683\n",
      "[4,  3400] loss: 5.644\n",
      "[4,  3500] loss: 5.704\n",
      "[4,  3600] loss: 5.668\n",
      "[4,  3700] loss: 5.614\n",
      "[4,  3800] loss: 5.658\n",
      "[4,  3900] loss: 5.728\n",
      "[4,  4000] loss: 5.680\n",
      "[4,  4100] loss: 5.665\n",
      "[4,  4200] loss: 5.652\n",
      "[4,  4300] loss: 5.649\n",
      "[4,  4400] loss: 5.712\n",
      "[4,  4500] loss: 5.669\n",
      "[4,  4600] loss: 5.674\n",
      "[4,  4700] loss: 5.644\n",
      "[4,  4800] loss: 5.663\n",
      "[4,  4900] loss: 5.660\n",
      "[4,  5000] loss: 5.625\n",
      "[4,  5100] loss: 5.615\n",
      "[4,  5200] loss: 5.616\n",
      "[4,  5300] loss: 5.620\n",
      "[4,  5400] loss: 5.692\n",
      "[4,  5500] loss: 5.695\n",
      "[5,   100] loss: 5.690\n",
      "[5,   200] loss: 5.608\n",
      "[5,   300] loss: 5.665\n",
      "[5,   400] loss: 5.722\n",
      "[5,   500] loss: 5.656\n",
      "[5,   600] loss: 5.663\n",
      "[5,   700] loss: 5.641\n",
      "[5,   800] loss: 5.626\n",
      "[5,   900] loss: 5.639\n",
      "[5,  1000] loss: 5.612\n",
      "[5,  1100] loss: 5.680\n",
      "[5,  1200] loss: 5.630\n",
      "[5,  1300] loss: 5.655\n",
      "[5,  1400] loss: 5.617\n",
      "[5,  1500] loss: 5.569\n",
      "[5,  1600] loss: 5.629\n",
      "[5,  1700] loss: 5.701\n",
      "[5,  1800] loss: 5.681\n",
      "[5,  1900] loss: 5.733\n",
      "[5,  2000] loss: 5.652\n",
      "[5,  2100] loss: 5.672\n",
      "[5,  2200] loss: 5.626\n",
      "[5,  2300] loss: 5.648\n",
      "[5,  2400] loss: 5.682\n",
      "[5,  2500] loss: 5.626\n",
      "[5,  2600] loss: 5.687\n",
      "[5,  2700] loss: 5.661\n",
      "[5,  2800] loss: 5.675\n",
      "[5,  2900] loss: 5.629\n",
      "[5,  3000] loss: 5.631\n",
      "[5,  3100] loss: 5.720\n",
      "[5,  3200] loss: 5.582\n",
      "[5,  3300] loss: 5.651\n",
      "[5,  3400] loss: 5.685\n",
      "[5,  3500] loss: 5.554\n",
      "[5,  3600] loss: 5.669\n",
      "[5,  3700] loss: 5.610\n",
      "[5,  3800] loss: 5.581\n",
      "[5,  3900] loss: 5.597\n",
      "[5,  4000] loss: 5.699\n",
      "[5,  4100] loss: 5.657\n",
      "[5,  4200] loss: 5.663\n",
      "[5,  4300] loss: 5.665\n",
      "[5,  4400] loss: 5.625\n",
      "[5,  4500] loss: 5.615\n",
      "[5,  4600] loss: 5.658\n",
      "[5,  4700] loss: 5.617\n",
      "[5,  4800] loss: 5.641\n",
      "[5,  4900] loss: 5.655\n",
      "[5,  5000] loss: 5.641\n",
      "[5,  5100] loss: 5.658\n",
      "[5,  5200] loss: 5.646\n",
      "[5,  5300] loss: 5.641\n",
      "[5,  5400] loss: 5.694\n",
      "[5,  5500] loss: 5.655\n",
      "[6,   100] loss: 5.559\n",
      "[6,   200] loss: 5.650\n",
      "[6,   300] loss: 5.658\n",
      "[6,   400] loss: 5.583\n",
      "[6,   500] loss: 5.552\n",
      "[6,   600] loss: 5.626\n",
      "[6,   700] loss: 5.642\n",
      "[6,   800] loss: 5.605\n",
      "[6,   900] loss: 5.645\n",
      "[6,  1000] loss: 5.619\n",
      "[6,  1100] loss: 5.654\n",
      "[6,  1200] loss: 5.752\n",
      "[6,  1300] loss: 5.671\n",
      "[6,  1400] loss: 5.667\n",
      "[6,  1500] loss: 5.665\n",
      "[6,  1600] loss: 5.623\n",
      "[6,  1700] loss: 5.662\n",
      "[6,  1800] loss: 5.564\n",
      "[6,  1900] loss: 5.615\n",
      "[6,  2000] loss: 5.623\n",
      "[6,  2100] loss: 5.578\n",
      "[6,  2200] loss: 5.560\n",
      "[6,  2300] loss: 5.581\n",
      "[6,  2400] loss: 5.643\n",
      "[6,  2500] loss: 5.665\n",
      "[6,  2600] loss: 5.625\n",
      "[6,  2700] loss: 5.606\n",
      "[6,  2800] loss: 5.604\n",
      "[6,  2900] loss: 5.632\n",
      "[6,  3000] loss: 5.658\n",
      "[6,  3100] loss: 5.644\n",
      "[6,  3200] loss: 5.691\n",
      "[6,  3300] loss: 5.636\n",
      "[6,  3400] loss: 5.639\n",
      "[6,  3500] loss: 5.691\n",
      "[6,  3600] loss: 5.667\n",
      "[6,  3700] loss: 5.630\n",
      "[6,  3800] loss: 5.629\n",
      "[6,  3900] loss: 5.649\n",
      "[6,  4000] loss: 5.653\n",
      "[6,  4100] loss: 5.622\n",
      "[6,  4200] loss: 5.640\n",
      "[6,  4300] loss: 5.626\n",
      "[6,  4400] loss: 5.652\n",
      "[6,  4500] loss: 5.658\n",
      "[6,  4600] loss: 5.594\n",
      "[6,  4700] loss: 5.682\n",
      "[6,  4800] loss: 5.651\n",
      "[6,  4900] loss: 5.665\n",
      "[6,  5000] loss: 5.650\n",
      "[6,  5100] loss: 5.587\n",
      "[6,  5200] loss: 5.641\n",
      "[6,  5300] loss: 5.660\n",
      "[6,  5400] loss: 5.675\n",
      "[6,  5500] loss: 5.576\n",
      "[7,   100] loss: 5.645\n",
      "[7,   200] loss: 5.625\n",
      "[7,   300] loss: 5.613\n",
      "[7,   400] loss: 5.564\n",
      "[7,   500] loss: 5.606\n",
      "[7,   600] loss: 5.586\n",
      "[7,   700] loss: 5.703\n",
      "[7,   800] loss: 5.596\n",
      "[7,   900] loss: 5.576\n",
      "[7,  1000] loss: 5.585\n",
      "[7,  1100] loss: 5.584\n",
      "[7,  1200] loss: 5.712\n",
      "[7,  1300] loss: 5.613\n",
      "[7,  1400] loss: 5.684\n",
      "[7,  1500] loss: 5.616\n",
      "[7,  1600] loss: 5.588\n",
      "[7,  1700] loss: 5.646\n",
      "[7,  1800] loss: 5.586\n",
      "[7,  1900] loss: 5.588\n",
      "[7,  2000] loss: 5.624\n",
      "[7,  2100] loss: 5.705\n",
      "[7,  2200] loss: 5.560\n",
      "[7,  2300] loss: 5.607\n",
      "[7,  2400] loss: 5.542\n",
      "[7,  2500] loss: 5.559\n",
      "[7,  2600] loss: 5.553\n",
      "[7,  2700] loss: 5.577\n",
      "[7,  2800] loss: 5.590\n",
      "[7,  2900] loss: 5.594\n",
      "[7,  3000] loss: 5.601\n",
      "[7,  3100] loss: 5.607\n",
      "[7,  3200] loss: 5.642\n",
      "[7,  3300] loss: 5.617\n",
      "[7,  3400] loss: 5.677\n",
      "[7,  3500] loss: 5.595\n",
      "[7,  3600] loss: 5.606\n",
      "[7,  3700] loss: 5.603\n",
      "[7,  3800] loss: 5.600\n",
      "[7,  3900] loss: 5.585\n",
      "[7,  4000] loss: 5.618\n",
      "[7,  4100] loss: 5.629\n",
      "[7,  4200] loss: 5.596\n",
      "[7,  4300] loss: 5.601\n",
      "[7,  4400] loss: 5.634\n",
      "[7,  4500] loss: 5.568\n",
      "[7,  4600] loss: 5.579\n",
      "[7,  4700] loss: 5.596\n",
      "[7,  4800] loss: 5.667\n",
      "[7,  4900] loss: 5.578\n",
      "[7,  5000] loss: 5.564\n",
      "[7,  5100] loss: 5.534\n",
      "[7,  5200] loss: 5.596\n",
      "[7,  5300] loss: 5.566\n",
      "[7,  5400] loss: 5.650\n",
      "[7,  5500] loss: 5.607\n",
      "[8,   100] loss: 5.620\n",
      "[8,   200] loss: 5.629\n",
      "[8,   300] loss: 5.594\n",
      "[8,   400] loss: 5.544\n",
      "[8,   500] loss: 5.593\n",
      "[8,   600] loss: 5.565\n",
      "[8,   700] loss: 5.448\n",
      "[8,   800] loss: 5.545\n",
      "[8,   900] loss: 5.546\n",
      "[8,  1000] loss: 5.668\n",
      "[8,  1100] loss: 5.633\n",
      "[8,  1200] loss: 5.605\n",
      "[8,  1300] loss: 5.544\n",
      "[8,  1400] loss: 5.525\n",
      "[8,  1500] loss: 5.569\n",
      "[8,  1600] loss: 5.636\n",
      "[8,  1700] loss: 5.604\n",
      "[8,  1800] loss: 5.547\n",
      "[8,  1900] loss: 5.634\n",
      "[8,  2000] loss: 5.574\n",
      "[8,  2100] loss: 5.648\n",
      "[8,  2200] loss: 5.645\n",
      "[8,  2300] loss: 5.693\n",
      "[8,  2400] loss: 5.612\n",
      "[8,  2500] loss: 5.632\n",
      "[8,  2600] loss: 5.575\n",
      "[8,  2700] loss: 5.614\n",
      "[8,  2800] loss: 5.577\n",
      "[8,  2900] loss: 5.567\n",
      "[8,  3000] loss: 5.566\n",
      "[8,  3100] loss: 5.608\n",
      "[8,  3200] loss: 5.576\n",
      "[8,  3300] loss: 5.589\n",
      "[8,  3400] loss: 5.624\n",
      "[8,  3500] loss: 5.663\n",
      "[8,  3600] loss: 5.543\n",
      "[8,  3700] loss: 5.603\n",
      "[8,  3800] loss: 5.630\n",
      "[8,  3900] loss: 5.567\n",
      "[8,  4000] loss: 5.527\n",
      "[8,  4100] loss: 5.641\n",
      "[8,  4200] loss: 5.637\n",
      "[8,  4300] loss: 5.632\n",
      "[8,  4400] loss: 5.605\n",
      "[8,  4500] loss: 5.600\n",
      "[8,  4600] loss: 5.597\n",
      "[8,  4700] loss: 5.564\n",
      "[8,  4800] loss: 5.551\n",
      "[8,  4900] loss: 5.639\n",
      "[8,  5000] loss: 5.594\n",
      "[8,  5100] loss: 5.597\n",
      "[8,  5200] loss: 5.616\n",
      "[8,  5300] loss: 5.615\n",
      "[8,  5400] loss: 5.551\n",
      "[8,  5500] loss: 5.589\n",
      "[9,   100] loss: 5.643\n",
      "[9,   200] loss: 5.596\n",
      "[9,   300] loss: 5.590\n",
      "[9,   400] loss: 5.574\n",
      "[9,   500] loss: 5.602\n",
      "[9,   600] loss: 5.554\n",
      "[9,   700] loss: 5.605\n",
      "[9,   800] loss: 5.593\n",
      "[9,   900] loss: 5.585\n",
      "[9,  1000] loss: 5.531\n",
      "[9,  1100] loss: 5.570\n",
      "[9,  1200] loss: 5.660\n",
      "[9,  1300] loss: 5.631\n",
      "[9,  1400] loss: 5.534\n",
      "[9,  1500] loss: 5.592\n",
      "[9,  1600] loss: 5.623\n",
      "[9,  1700] loss: 5.594\n",
      "[9,  1800] loss: 5.603\n",
      "[9,  1900] loss: 5.591\n",
      "[9,  2000] loss: 5.519\n",
      "[9,  2100] loss: 5.526\n",
      "[9,  2200] loss: 5.673\n",
      "[9,  2300] loss: 5.601\n",
      "[9,  2400] loss: 5.591\n",
      "[9,  2500] loss: 5.567\n",
      "[9,  2600] loss: 5.613\n",
      "[9,  2700] loss: 5.534\n",
      "[9,  2800] loss: 5.573\n",
      "[9,  2900] loss: 5.556\n",
      "[9,  3000] loss: 5.484\n",
      "[9,  3100] loss: 5.548\n",
      "[9,  3200] loss: 5.605\n",
      "[9,  3300] loss: 5.564\n",
      "[9,  3400] loss: 5.489\n",
      "[9,  3500] loss: 5.569\n",
      "[9,  3600] loss: 5.481\n",
      "[9,  3700] loss: 5.615\n",
      "[9,  3800] loss: 5.606\n",
      "[9,  3900] loss: 5.618\n",
      "[9,  4000] loss: 5.586\n",
      "[9,  4100] loss: 5.573\n",
      "[9,  4200] loss: 5.529\n",
      "[9,  4300] loss: 5.590\n",
      "[9,  4400] loss: 5.502\n",
      "[9,  4500] loss: 5.607\n",
      "[9,  4600] loss: 5.557\n",
      "[9,  4700] loss: 5.651\n",
      "[9,  4800] loss: 5.662\n",
      "[9,  4900] loss: 5.607\n",
      "[9,  5000] loss: 5.609\n",
      "[9,  5100] loss: 5.561\n",
      "[9,  5200] loss: 5.565\n",
      "[9,  5300] loss: 5.610\n",
      "[9,  5400] loss: 5.585\n",
      "[9,  5500] loss: 5.531\n",
      "[10,   100] loss: 5.622\n",
      "[10,   200] loss: 5.572\n",
      "[10,   300] loss: 5.556\n",
      "[10,   400] loss: 5.646\n",
      "[10,   500] loss: 5.596\n",
      "[10,   600] loss: 5.584\n",
      "[10,   700] loss: 5.524\n",
      "[10,   800] loss: 5.612\n",
      "[10,   900] loss: 5.527\n",
      "[10,  1000] loss: 5.554\n",
      "[10,  1100] loss: 5.501\n",
      "[10,  1200] loss: 5.509\n",
      "[10,  1300] loss: 5.532\n",
      "[10,  1400] loss: 5.558\n",
      "[10,  1500] loss: 5.581\n",
      "[10,  1600] loss: 5.586\n",
      "[10,  1700] loss: 5.523\n",
      "[10,  1800] loss: 5.602\n",
      "[10,  1900] loss: 5.566\n",
      "[10,  2000] loss: 5.595\n",
      "[10,  2100] loss: 5.543\n",
      "[10,  2200] loss: 5.588\n",
      "[10,  2300] loss: 5.556\n",
      "[10,  2400] loss: 5.528\n",
      "[10,  2500] loss: 5.629\n",
      "[10,  2600] loss: 5.586\n",
      "[10,  2700] loss: 5.535\n",
      "[10,  2800] loss: 5.576\n",
      "[10,  2900] loss: 5.586\n",
      "[10,  3000] loss: 5.598\n",
      "[10,  3100] loss: 5.541\n",
      "[10,  3200] loss: 5.612\n",
      "[10,  3300] loss: 5.594\n",
      "[10,  3400] loss: 5.561\n",
      "[10,  3500] loss: 5.533\n",
      "[10,  3600] loss: 5.578\n",
      "[10,  3700] loss: 5.589\n",
      "[10,  3800] loss: 5.541\n",
      "[10,  3900] loss: 5.531\n",
      "[10,  4000] loss: 5.594\n",
      "[10,  4100] loss: 5.491\n",
      "[10,  4200] loss: 5.549\n",
      "[10,  4300] loss: 5.571\n",
      "[10,  4400] loss: 5.549\n",
      "[10,  4500] loss: 5.552\n",
      "[10,  4600] loss: 5.538\n",
      "[10,  4700] loss: 5.630\n",
      "[10,  4800] loss: 5.611\n",
      "[10,  4900] loss: 5.586\n",
      "[10,  5000] loss: 5.535\n",
      "[10,  5100] loss: 5.536\n",
      "[10,  5200] loss: 5.506\n",
      "[10,  5300] loss: 5.568\n",
      "[10,  5400] loss: 5.545\n",
      "[10,  5500] loss: 5.598\n"
     ]
    }
   ],
   "source": [
    "train_network(model, train_loader, criterion, optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 2 %\n"
     ]
    }
   ],
   "source": [
    "test_network(model, test_loader)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "vscode": {
   "interpreter": {
    "hash": "87080e7cd9a8236934cf37ef16c9e0a38c6da99bf1ea92572cd195152db0d9e8"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
