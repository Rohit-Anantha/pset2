{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([44730, 11, 40])\n",
      "torch.Size([4773, 11, 40])\n",
      "torch.Size([44730])\n",
      "torch.Size([4773])\n",
      "(48,)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "# Load the dataset\n",
    "data = np.load('lab2_dataset.npz')\n",
    "train_feats = torch.tensor(data['train_feats'])\n",
    "test_feats = torch.tensor(data['test_feats'])\n",
    "train_labels = torch.tensor(data['train_labels'])\n",
    "test_labels = torch.tensor(data['test_labels'])\n",
    "phone_labels = data['phone_labels']\n",
    "\n",
    "print(train_feats.shape)\n",
    "print(test_feats.shape)\n",
    "print(train_labels.shape)\n",
    "print(test_labels.shape)\n",
    "print(phone_labels.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up the dataloaders\n",
    "train_dataset = torch.utils.data.TensorDataset(train_feats, train_labels)\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=8, shuffle=True)\n",
    "\n",
    "test_dataset = torch.utils.data.TensorDataset(test_feats, test_labels)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=8, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the model architecture\n",
    "class MyModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MyModel, self).__init__()\n",
    "        # TODO: Fill in the model's layers here\n",
    "        self.linear1 = nn.Linear(40, 64)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.linear2 = nn.Linear(64, 48)\n",
    "    def forward(self, x):\n",
    "        # TODO: Fill in the forward pass here\n",
    "        x = self.linear1(x)\n",
    "        x = self.relu1(x)\n",
    "        x = self.linear2(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the model, loss function, and optimizer\n",
    "model = MyModel()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "def train_network(model, train_loader, criterion, optimizer):\n",
    "    # TODO: fill in\n",
    "    for epoch in range(10):\n",
    "        running_loss = 0.0\n",
    "        for i, (inputs, labels) in enumerate(train_loader, 0):\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "            if i % 100 == 99:\n",
    "                print('[%d, %5d] loss: %.3f' % (epoch + 1, i + 1, running_loss / 100))\n",
    "                running_loss = 0.0\n",
    "\n",
    "def test_network(model, test_loader):\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for data in test_loader:\n",
    "            inputs, labels = data\n",
    "            outputs = model(inputs)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    print('Test accuracy: %d %%' % (100 * correct / total))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,   100] loss: 7.492\n",
      "[1,   200] loss: 6.276\n",
      "[1,   300] loss: 6.268\n",
      "[1,   400] loss: 6.271\n",
      "[1,   500] loss: 6.265\n",
      "[1,   600] loss: 6.265\n",
      "[1,   700] loss: 6.271\n",
      "[1,   800] loss: 6.264\n",
      "[1,   900] loss: 6.264\n",
      "[1,  1000] loss: 6.266\n",
      "[1,  1100] loss: 6.265\n",
      "[1,  1200] loss: 6.264\n",
      "[1,  1300] loss: 6.263\n",
      "[1,  1400] loss: 6.263\n",
      "[1,  1500] loss: 6.260\n",
      "[1,  1600] loss: 6.264\n",
      "[1,  1700] loss: 6.261\n",
      "[1,  1800] loss: 6.263\n",
      "[1,  1900] loss: 6.261\n",
      "[1,  2000] loss: 6.261\n",
      "[1,  2100] loss: 6.258\n",
      "[1,  2200] loss: 6.258\n",
      "[1,  2300] loss: 6.258\n",
      "[1,  2400] loss: 6.256\n",
      "[1,  2500] loss: 6.259\n",
      "[1,  2600] loss: 6.259\n",
      "[1,  2700] loss: 6.258\n",
      "[1,  2800] loss: 6.257\n",
      "[1,  2900] loss: 6.256\n",
      "[1,  3000] loss: 6.256\n",
      "[1,  3100] loss: 6.256\n",
      "[1,  3200] loss: 6.255\n",
      "[1,  3300] loss: 6.257\n",
      "[1,  3400] loss: 6.251\n",
      "[1,  3500] loss: 6.256\n",
      "[1,  3600] loss: 6.255\n",
      "[1,  3700] loss: 6.258\n",
      "[1,  3800] loss: 6.253\n",
      "[1,  3900] loss: 6.254\n",
      "[1,  4000] loss: 6.250\n",
      "[1,  4100] loss: 6.254\n",
      "[1,  4200] loss: 6.254\n",
      "[1,  4300] loss: 6.252\n",
      "[1,  4400] loss: 6.257\n",
      "[1,  4500] loss: 6.256\n",
      "[1,  4600] loss: 6.257\n",
      "[1,  4700] loss: 6.255\n",
      "[1,  4800] loss: 6.256\n",
      "[1,  4900] loss: 6.252\n",
      "[1,  5000] loss: 6.255\n",
      "[1,  5100] loss: 6.251\n",
      "[1,  5200] loss: 6.255\n",
      "[1,  5300] loss: 6.246\n",
      "[1,  5400] loss: 6.253\n",
      "[1,  5500] loss: 6.250\n",
      "[2,   100] loss: 6.244\n",
      "[2,   200] loss: 6.249\n",
      "[2,   300] loss: 6.251\n",
      "[2,   400] loss: 6.252\n",
      "[2,   500] loss: 6.251\n",
      "[2,   600] loss: 6.253\n",
      "[2,   700] loss: 6.249\n",
      "[2,   800] loss: 6.251\n",
      "[2,   900] loss: 6.250\n",
      "[2,  1000] loss: 6.246\n",
      "[2,  1100] loss: 6.251\n",
      "[2,  1200] loss: 6.250\n",
      "[2,  1300] loss: 6.250\n",
      "[2,  1400] loss: 6.246\n",
      "[2,  1500] loss: 6.250\n",
      "[2,  1600] loss: 6.247\n",
      "[2,  1700] loss: 6.255\n",
      "[2,  1800] loss: 6.244\n",
      "[2,  1900] loss: 6.251\n",
      "[2,  2000] loss: 6.253\n",
      "[2,  2100] loss: 6.251\n",
      "[2,  2200] loss: 6.244\n",
      "[2,  2300] loss: 6.257\n",
      "[2,  2400] loss: 6.250\n",
      "[2,  2500] loss: 6.246\n",
      "[2,  2600] loss: 6.252\n",
      "[2,  2700] loss: 6.251\n",
      "[2,  2800] loss: 6.254\n",
      "[2,  2900] loss: 6.243\n",
      "[2,  3000] loss: 6.248\n",
      "[2,  3100] loss: 6.251\n",
      "[2,  3200] loss: 6.247\n",
      "[2,  3300] loss: 6.244\n",
      "[2,  3400] loss: 6.241\n",
      "[2,  3500] loss: 6.238\n",
      "[2,  3600] loss: 6.254\n",
      "[2,  3700] loss: 6.243\n",
      "[2,  3800] loss: 6.248\n",
      "[2,  3900] loss: 6.248\n",
      "[2,  4000] loss: 6.250\n",
      "[2,  4100] loss: 6.245\n",
      "[2,  4200] loss: 6.246\n",
      "[2,  4300] loss: 6.247\n",
      "[2,  4400] loss: 6.254\n",
      "[2,  4500] loss: 6.246\n",
      "[2,  4600] loss: 6.248\n",
      "[2,  4700] loss: 6.242\n",
      "[2,  4800] loss: 6.242\n",
      "[2,  4900] loss: 6.254\n",
      "[2,  5000] loss: 6.245\n",
      "[2,  5100] loss: 6.241\n",
      "[2,  5200] loss: 6.246\n",
      "[2,  5300] loss: 6.189\n",
      "[2,  5400] loss: 6.120\n",
      "[2,  5500] loss: 6.183\n",
      "[3,   100] loss: 6.106\n",
      "[3,   200] loss: 6.113\n",
      "[3,   300] loss: 6.111\n",
      "[3,   400] loss: 6.123\n",
      "[3,   500] loss: 6.120\n",
      "[3,   600] loss: 6.158\n",
      "[3,   700] loss: 6.135\n",
      "[3,   800] loss: 6.089\n",
      "[3,   900] loss: 6.116\n",
      "[3,  1000] loss: 6.120\n",
      "[3,  1100] loss: 6.147\n",
      "[3,  1200] loss: 6.097\n",
      "[3,  1300] loss: 6.125\n",
      "[3,  1400] loss: 6.079\n",
      "[3,  1500] loss: 6.118\n",
      "[3,  1600] loss: 6.244\n",
      "[3,  1700] loss: 6.255\n",
      "[3,  1800] loss: 6.249\n",
      "[3,  1900] loss: 6.193\n",
      "[3,  2000] loss: 6.112\n",
      "[3,  2100] loss: 6.100\n",
      "[3,  2200] loss: 6.132\n",
      "[3,  2300] loss: 6.113\n",
      "[3,  2400] loss: 6.150\n",
      "[3,  2500] loss: 6.113\n",
      "[3,  2600] loss: 6.087\n",
      "[3,  2700] loss: 6.098\n",
      "[3,  2800] loss: 6.090\n",
      "[3,  2900] loss: 6.128\n",
      "[3,  3000] loss: 6.126\n",
      "[3,  3100] loss: 6.085\n",
      "[3,  3200] loss: 6.118\n",
      "[3,  3300] loss: 6.083\n",
      "[3,  3400] loss: 6.071\n",
      "[3,  3500] loss: 6.088\n",
      "[3,  3600] loss: 6.189\n",
      "[3,  3700] loss: 6.113\n",
      "[3,  3800] loss: 6.104\n",
      "[3,  3900] loss: 6.116\n",
      "[3,  4000] loss: 6.125\n",
      "[3,  4100] loss: 6.110\n",
      "[3,  4200] loss: 6.114\n",
      "[3,  4300] loss: 6.083\n",
      "[3,  4400] loss: 6.128\n",
      "[3,  4500] loss: 6.169\n",
      "[3,  4600] loss: 6.093\n",
      "[3,  4700] loss: 6.109\n",
      "[3,  4800] loss: 6.060\n",
      "[3,  4900] loss: 6.096\n",
      "[3,  5000] loss: 6.094\n",
      "[3,  5100] loss: 6.117\n",
      "[3,  5200] loss: 6.098\n",
      "[3,  5300] loss: 6.159\n",
      "[3,  5400] loss: 6.082\n",
      "[3,  5500] loss: 6.107\n",
      "[4,   100] loss: 6.140\n",
      "[4,   200] loss: 6.103\n",
      "[4,   300] loss: 6.095\n",
      "[4,   400] loss: 6.082\n",
      "[4,   500] loss: 6.040\n",
      "[4,   600] loss: 6.079\n",
      "[4,   700] loss: 6.107\n",
      "[4,   800] loss: 6.123\n",
      "[4,   900] loss: 6.128\n",
      "[4,  1000] loss: 6.054\n",
      "[4,  1100] loss: 6.085\n",
      "[4,  1200] loss: 6.118\n",
      "[4,  1300] loss: 6.285\n",
      "[4,  1400] loss: 6.246\n",
      "[4,  1500] loss: 6.272\n",
      "[4,  1600] loss: 6.257\n",
      "[4,  1700] loss: 6.259\n",
      "[4,  1800] loss: 6.267\n",
      "[4,  1900] loss: 6.273\n",
      "[4,  2000] loss: 6.267\n",
      "[4,  2100] loss: 6.259\n",
      "[4,  2200] loss: 6.249\n",
      "[4,  2300] loss: 6.258\n",
      "[4,  2400] loss: 6.267\n",
      "[4,  2500] loss: 6.253\n",
      "[4,  2600] loss: 6.256\n",
      "[4,  2700] loss: 6.278\n",
      "[4,  2800] loss: 6.254\n",
      "[4,  2900] loss: 6.255\n",
      "[4,  3000] loss: 6.267\n",
      "[4,  3100] loss: 6.262\n",
      "[4,  3200] loss: 6.258\n",
      "[4,  3300] loss: 6.250\n",
      "[4,  3400] loss: 6.261\n",
      "[4,  3500] loss: 6.257\n",
      "[4,  3600] loss: 6.262\n",
      "[4,  3700] loss: 6.252\n",
      "[4,  3800] loss: 6.261\n",
      "[4,  3900] loss: 6.240\n",
      "[4,  4000] loss: 6.263\n",
      "[4,  4100] loss: 6.252\n",
      "[4,  4200] loss: 6.257\n",
      "[4,  4300] loss: 6.259\n",
      "[4,  4400] loss: 6.242\n",
      "[4,  4500] loss: 6.255\n",
      "[4,  4600] loss: 6.255\n",
      "[4,  4700] loss: 6.264\n",
      "[4,  4800] loss: 6.255\n",
      "[4,  4900] loss: 6.252\n",
      "[4,  5000] loss: 6.241\n",
      "[4,  5100] loss: 6.251\n",
      "[4,  5200] loss: 6.257\n",
      "[4,  5300] loss: 6.248\n",
      "[4,  5400] loss: 6.242\n",
      "[4,  5500] loss: 6.251\n",
      "[5,   100] loss: 6.248\n",
      "[5,   200] loss: 6.245\n",
      "[5,   300] loss: 6.246\n",
      "[5,   400] loss: 6.244\n",
      "[5,   500] loss: 6.243\n",
      "[5,   600] loss: 6.253\n",
      "[5,   700] loss: 6.243\n",
      "[5,   800] loss: 6.258\n",
      "[5,   900] loss: 6.247\n",
      "[5,  1000] loss: 6.243\n",
      "[5,  1100] loss: 6.247\n",
      "[5,  1200] loss: 6.242\n",
      "[5,  1300] loss: 6.247\n",
      "[5,  1400] loss: 6.249\n",
      "[5,  1500] loss: 6.240\n",
      "[5,  1600] loss: 6.248\n",
      "[5,  1700] loss: 6.256\n",
      "[5,  1800] loss: 6.251\n",
      "[5,  1900] loss: 6.249\n",
      "[5,  2000] loss: 6.233\n",
      "[5,  2100] loss: 6.253\n",
      "[5,  2200] loss: 6.243\n",
      "[5,  2300] loss: 6.236\n",
      "[5,  2400] loss: 6.240\n",
      "[5,  2500] loss: 6.247\n",
      "[5,  2600] loss: 6.244\n",
      "[5,  2700] loss: 6.250\n",
      "[5,  2800] loss: 6.260\n",
      "[5,  2900] loss: 6.244\n",
      "[5,  3000] loss: 6.266\n",
      "[5,  3100] loss: 6.243\n",
      "[5,  3200] loss: 6.250\n",
      "[5,  3300] loss: 6.249\n",
      "[5,  3400] loss: 6.258\n",
      "[5,  3500] loss: 6.242\n",
      "[5,  3600] loss: 6.240\n",
      "[5,  3700] loss: 6.249\n",
      "[5,  3800] loss: 6.245\n",
      "[5,  3900] loss: 6.255\n",
      "[5,  4000] loss: 6.242\n",
      "[5,  4100] loss: 6.249\n",
      "[5,  4200] loss: 6.245\n",
      "[5,  4300] loss: 6.243\n",
      "[5,  4400] loss: 6.247\n",
      "[5,  4500] loss: 6.243\n",
      "[5,  4600] loss: 6.245\n",
      "[5,  4700] loss: 6.246\n",
      "[5,  4800] loss: 6.257\n",
      "[5,  4900] loss: 6.253\n",
      "[5,  5000] loss: 6.246\n",
      "[5,  5100] loss: 6.242\n",
      "[5,  5200] loss: 6.239\n",
      "[5,  5300] loss: 6.239\n",
      "[5,  5400] loss: 6.249\n",
      "[5,  5500] loss: 6.248\n",
      "[6,   100] loss: 6.247\n",
      "[6,   200] loss: 6.241\n",
      "[6,   300] loss: 6.245\n",
      "[6,   400] loss: 6.246\n",
      "[6,   500] loss: 6.234\n",
      "[6,   600] loss: 6.247\n",
      "[6,   700] loss: 6.237\n",
      "[6,   800] loss: 6.243\n",
      "[6,   900] loss: 6.255\n",
      "[6,  1000] loss: 6.240\n",
      "[6,  1100] loss: 6.244\n",
      "[6,  1200] loss: 6.251\n",
      "[6,  1300] loss: 6.242\n",
      "[6,  1400] loss: 6.256\n",
      "[6,  1500] loss: 6.245\n",
      "[6,  1600] loss: 6.244\n",
      "[6,  1700] loss: 6.243\n",
      "[6,  1800] loss: 6.241\n",
      "[6,  1900] loss: 6.237\n",
      "[6,  2000] loss: 6.244\n",
      "[6,  2100] loss: 6.237\n",
      "[6,  2200] loss: 6.243\n",
      "[6,  2300] loss: 6.244\n",
      "[6,  2400] loss: 6.245\n",
      "[6,  2500] loss: 6.239\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[59], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m train_network(model, train_loader, criterion, optimizer)\n",
      "Cell \u001b[0;32mIn[58], line 10\u001b[0m, in \u001b[0;36mtrain_network\u001b[0;34m(model, train_loader, criterion, optimizer)\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[39mfor\u001b[39;00m epoch \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m10\u001b[39m):\n\u001b[1;32m      9\u001b[0m     running_loss \u001b[39m=\u001b[39m \u001b[39m0.0\u001b[39m\n\u001b[0;32m---> 10\u001b[0m     \u001b[39mfor\u001b[39;00m i, (inputs, labels) \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(train_loader, \u001b[39m0\u001b[39m):\n\u001b[1;32m     11\u001b[0m         optimizer\u001b[39m.\u001b[39mzero_grad()\n\u001b[1;32m     12\u001b[0m         outputs \u001b[39m=\u001b[39m model(inputs)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/tf/lib/python3.10/site-packages/torch/utils/data/dataloader.py:628\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    625\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sampler_iter \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    626\u001b[0m     \u001b[39m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    627\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reset()  \u001b[39m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 628\u001b[0m data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_next_data()\n\u001b[1;32m    629\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m    630\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dataset_kind \u001b[39m==\u001b[39m _DatasetKind\u001b[39m.\u001b[39mIterable \u001b[39mand\u001b[39;00m \\\n\u001b[1;32m    631\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \\\n\u001b[1;32m    632\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m>\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/tf/lib/python3.10/site-packages/torch/utils/data/dataloader.py:671\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    669\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_next_data\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m    670\u001b[0m     index \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_next_index()  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 671\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_dataset_fetcher\u001b[39m.\u001b[39;49mfetch(index)  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    672\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory:\n\u001b[1;32m    673\u001b[0m         data \u001b[39m=\u001b[39m _utils\u001b[39m.\u001b[39mpin_memory\u001b[39m.\u001b[39mpin_memory(data, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/tf/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py:58\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     56\u001b[0m         data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset\u001b[39m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     57\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m---> 58\u001b[0m         data \u001b[39m=\u001b[39m [\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[idx] \u001b[39mfor\u001b[39;00m idx \u001b[39min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     59\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     60\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/tf/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py:58\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     56\u001b[0m         data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset\u001b[39m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     57\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m---> 58\u001b[0m         data \u001b[39m=\u001b[39m [\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdataset[idx] \u001b[39mfor\u001b[39;00m idx \u001b[39min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     59\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     60\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/tf/lib/python3.10/site-packages/torch/utils/data/dataset.py:193\u001b[0m, in \u001b[0;36mTensorDataset.__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m    192\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__getitem__\u001b[39m(\u001b[39mself\u001b[39m, index):\n\u001b[0;32m--> 193\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mtuple\u001b[39m(tensor[index] \u001b[39mfor\u001b[39;00m tensor \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtensors)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train_network(model, train_loader, criterion, optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n"
     ]
    }
   ],
   "source": [
    "test = 10\n",
    "print(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 0 %\n"
     ]
    }
   ],
   "source": [
    "test_network(model, test_loader)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "vscode": {
   "interpreter": {
    "hash": "87080e7cd9a8236934cf37ef16c9e0a38c6da99bf1ea92572cd195152db0d9e8"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
